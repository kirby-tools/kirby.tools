---
title: Global Options
description: Configure the AI provider, API keys, model, temperature and more.
---

## Properties

The Kirby Copilot plugin can be configured globally in the `config.php` file of your Kirby project. All options are nested under the `johannschopplich.copilot` key.

```php [config.php]
return [
    'johannschopplich.copilot' => [
        // Customize Kirby Copilot
    ]
];
```

All possible options have reasonable defaults. Only if you want to change the default behavior, you need to add the option to your configuration.

The following list contains all available options:

### `provider` :u-badge{label="String" class="align-middle ml-2 !rounded-full" variant="subtle"}

The `provider` option defines the AI model provider that will be used to generate content across all Copilot sections. The plugin supports two providers:

- `openai` (default)
- `anthropic`
- `mistral`

By default, the `openai` provider is used. To change the provider, such as [Anthropic Claude](https://www.anthropic.com/claude) or [Mistral AI](https://mistral.ai), you need to add the configuration for the respective provider:

```php [config.php]
return [
    'johannschopplich.copilot' => [
        'provider' => 'anthropic',
        'providers' => [
            'anthropic' => [
                'apiKey' => 'YOUR_API_KEY',
                'model' => 'claude-3-5-sonnet-20240620'
            ]
        ]
    ]
];
```

::callout{icon="i-ri-lightbulb-line"}
We will add support for other AI providers if there is enough demand.
::

### `providers` :u-badge{label="Array" class="align-middle ml-2 !rounded-full" variant="subtle"}

#### `apiKey` :u-badge{label="String" class="align-middle ml-2 !rounded-full" variant="subtle"}

The `providers` option holds the configuration for each AI provider, such as the AI model to use for text generation. A valid API key is required for Kirby Copilot to make requests to the AI provider.

::callout{icon="i-ri-lightbulb-line"}
You can get an API key for GPT models by registering for the [OpenAI API](https://platform.openai.com).
::

No API key is provided by default. Please be sure to add your API key to the configuration:

```php [config.php]
return [
    'johannschopplich.copilot' => [
        'providers' => [
            'openai' => [
                'apiKey' => 'YOUR_API_KEY'
            ]
        ]
    ]
];
```

::callout{icon="i-ri-error-warning-line" color="amber"}
It is highly recommended to create API keys for each Kirby project (and client), because the AI requests are sent from the client-side and could be abused by malicious users.
::

#### `model` :u-badge{label="String" class="align-middle ml-2 !rounded-full" variant="subtle"}

The `model` option defines the provider model used to generate content. In the case of OpenAI, the default configuration uses the `o3-mini` model:

```php [config.php]
return [
    'johannschopplich.copilot' => [
        'providers' => [
            'openai' => [
                'model' => 'o3-mini'
            ]
        ]
    ]
];
```

For example, if you prefer the `gpt-4o` model to support images as input for content generation, you can change the default model:

```php [config.php]
return [
    'johannschopplich.copilot' => [
        'providers' => [
            'openai' => [
                'model' => 'gpt-4o'
            ]
        ]
    ]
];
```

#### `baseUrl` :u-badge{label="String" class="align-middle ml-2 !rounded-full" variant="subtle"}

The optional `baseUrl` option applies to the Mistral provider and lets you define the base URL of a custom Mistral API instance.

### `temperature` :u-badge{label="Float" class="align-middle ml-2 !rounded-full" variant="subtle"}

The `temperature` option defines the randomness of the generated content. The higher the temperature, the more random the generated content will be.

The default value is `0.7`.

If you want the model to be more creative, you can increase the temperature:

```php [config.php]
return [
    'johannschopplich.copilot' => [
        'temperature' => 1
    ]
];
```

### `systemPrompt` :u-badge{label="String" class="align-middle ml-2 !rounded-full" variant="subtle"}

The `systemPrompt` is probably the most important configuration option besides the `model`. It is the structural foundation of the generated content and complements the prompt that is provided by the user ([`userPrompt` section property](/docs/configuration/section)).

With Kirby Copilot v2, the system prompt has been redesigned to accommodate all use cases without the need for manual configuration. The system prompt is designed to instruct the AI model on how to structure the generated text and what context to consider.

::callout{icon="i-ri-ai-generate" to="/docs/configuration/system-prompt"}
Learn more about the system prompt and how to customize it.
::

### `blocksUpdateThrottle` :u-badge{label="Integer" class="align-middle ml-2 !rounded-full" variant="subtle"}

The `blocksUpdateThrottle` option defines the number of milliseconds that the plugin will wait before updating the blocks field with new generated content.

The default value is `250`. Any value below `50` will be capped to `50`.

A minimum throttle interval is required to avoid performance issues, because the HTML to blocks conversion is done via an internal API route.

## Configuration Example

As a reference, below is an example of a complete configuration with the most common options:

```php [config.php]
return [
    'johannschopplich.copilot' => [
        'provider' => 'openai',
        'providers' => [
            'openai' => [
                'model' => 'gpt-4o',
                'apiKey' => 'YOUR_API_KEY'
            ]
        ],
        'temperature' => 0.7,
        'blocksUpdateThrottle' => 250
    ]
];
```
